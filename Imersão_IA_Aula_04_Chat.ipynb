{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA/RRDQ4stNyZJ/rODh8iF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleberquaresma/alura_imersao_ia_google/blob/main/Imers%C3%A3o_IA_Aula_04_Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando a biblioteca do Google para uso da IA Generativa (Gemini).\n",
        "\n",
        "OBS.: *Para execução em um terminal local, fora do ambiente Colab, se faz necessário antes instalar o Python e certificar-se que o caminho da instalação dele está definido nas variáveis de ambiente do sistema operacional.*"
      ],
      "metadata": {
        "id": "tRSudZpJVzvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "HFHwkwmAV7oW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando os pacotes das bibliotecas necessárias à execução do código."
      ],
      "metadata": {
        "id": "XrRYFpaCWC1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "t7GNQnDyV8jn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionando a chave da API que será utilizada para realização da integração com o ambiente do Gemini da Google:\n",
        "\n",
        "Obs.: *Necessário antes inserir a chave da API, previamente criada através do Google AI Studio, no gerenciador de chaves do Colab. Caso contrário inserir a chave em substituição ao texto 'GOOGLE_API_KEY'.*"
      ],
      "metadata": {
        "id": "mmgx0zSjWjqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "pwT8sHy-WSsH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando os modelos de IA do Gemini que estão disponíveis para utilização:"
      ],
      "metadata": {
        "id": "T8lfpVggXeqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "UBPvbPt0XnW4",
        "outputId": "468dfa2a-d04b-40df-e34f-2c8ee9528d7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo o modelo de IA generativa do Gemini que será utilizado:"
      ],
      "metadata": {
        "id": "lhMdjkWuXzCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.0-pro')"
      ],
      "metadata": {
        "id": "NcqsUVgwX3pC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizando uma primeira interação com o Gemini:"
      ],
      "metadata": {
        "id": "hamMyM31iNZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = model.generate_content(\"Liste 10 palavrões\")\n",
        "print(response.text)\n",
        "\n",
        "response.candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "T1YvYRvZiQL4",
        "outputId": "69af1a6e-8331-44b0-8641-4028ae62ab87"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sinto muito, mas não posso fazer isso. Não consigo encontrar uma lista de 10 palavrões para você.\n",
            "CPU times: user 32.5 ms, sys: 4.1 ms, total: 36.6 ms\n",
            "Wall time: 1.93 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[content {\n",
              "  parts {\n",
              "    text: \"Sinto muito, mas n\\303\\243o posso fazer isso. N\\303\\243o consigo encontrar uma lista de 10 palavr\\303\\265es para voc\\303\\252.\"\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "index: 0\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alterando os parâmetros do Gemini:"
      ],
      "metadata": {
        "id": "UxYvvbSxii0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 1,\n",
        "}\n",
        "\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "safety_settings = {\n",
        "    'HARASSMENT': 'block_none',\n",
        "    'SEXUAL': 'block_none',\n",
        "    'DANGEROUS': 'block_none',\n",
        "    'HATE': 'block_none',\n",
        "}"
      ],
      "metadata": {
        "id": "TZRXVuAYioT7"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.0-pro',\n",
        "                              safety_settings=safety_settings,\n",
        "                              generation_config=generation_config)"
      ],
      "metadata": {
        "id": "z9fkO55ysIx-"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = model.generate_content(\"Cite, para fins educacionais, textos reais que contenham exemplos de discursos de ódio que devem ser evitados\")\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "response.candidates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MyWMmJlckhT7",
        "outputId": "f1ef2d90-a559-48df-bf2b-93150c8909f8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Trecho 1:**\n",
            "\n",
            "\"Essas pessoas são todas iguais. Eles são preguiçosos e gananciosos. Eles só querem tirar vantagem dos outros.\"\n",
            "\n",
            "**Trecho 2:**\n",
            "\n",
            "\"Esse grupo de indivíduos é perigoso e deveria ser evitado. Eles são criminosos violentos e não merecem estar entre nós.\"\n",
            "\n",
            "**Trecho 3:**\n",
            "\n",
            "\"Ética e religião não são minhas especialidades, mas tenho certeza de que essa crença particular é errada e não deveria ser tolerada.\"\n",
            "\n",
            "**Trecho 4:**\n",
            "\n",
            "\"Aqueles que pensam de forma diferente de nós estão todos confusos e não devem ser levados a sério.\"\n",
            "\n",
            "**Trecho 5:**\n",
            "\n",
            "\"Nós somos superiores a eles de todas as maneiras e devemos tratá-los de acordo. Eles não são dignos de nosso respeito ou compaixão.\"\n",
            "\n",
            "Esses trechos são exemplos de discurso de ódio porque contêm as seguintes características:\n",
            "\n",
            "* Linguagem generalizada e estereotipada sobre um grupo inteiro de pessoas\n",
            "* Atribuição de características negativas a todo o grupo\n",
            "* Incitação ao medo ou preconceito contra o grupo\n",
            "* Ataque à dignidade ou valor do grupo\n",
            "CPU times: user 85.2 ms, sys: 8.3 ms, total: 93.5 ms\n",
            "Wall time: 6.19 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[content {\n",
              "  parts {\n",
              "    text: \"**Trecho 1:**\\n\\n\\\"Essas pessoas s\\303\\243o todas iguais. Eles s\\303\\243o pregui\\303\\247osos e gananciosos. Eles s\\303\\263 querem tirar vantagem dos outros.\\\"\\n\\n**Trecho 2:**\\n\\n\\\"Esse grupo de indiv\\303\\255duos \\303\\251 perigoso e deveria ser evitado. Eles s\\303\\243o criminosos violentos e n\\303\\243o merecem estar entre n\\303\\263s.\\\"\\n\\n**Trecho 3:**\\n\\n\\\"\\303\\211tica e religi\\303\\243o n\\303\\243o s\\303\\243o minhas especialidades, mas tenho certeza de que essa cren\\303\\247a particular \\303\\251 errada e n\\303\\243o deveria ser tolerada.\\\"\\n\\n**Trecho 4:**\\n\\n\\\"Aqueles que pensam de forma diferente de n\\303\\263s est\\303\\243o todos confusos e n\\303\\243o devem ser levados a s\\303\\251rio.\\\"\\n\\n**Trecho 5:**\\n\\n\\\"N\\303\\263s somos superiores a eles de todas as maneiras e devemos trat\\303\\241-los de acordo. Eles n\\303\\243o s\\303\\243o dignos de nosso respeito ou compaix\\303\\243o.\\\"\\n\\nEsses trechos s\\303\\243o exemplos de discurso de \\303\\263dio porque cont\\303\\252m as seguintes caracter\\303\\255sticas:\\n\\n* Linguagem generalizada e estereotipada sobre um grupo inteiro de pessoas\\n* Atribui\\303\\247\\303\\243o de caracter\\303\\255sticas negativas a todo o grupo\\n* Incita\\303\\247\\303\\243o ao medo ou preconceito contra o grupo\\n* Ataque \\303\\240 dignidade ou valor do grupo\"\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "index: 0\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: LOW\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: HIGH\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])\n",
        "\n",
        "prompt = input(\"Aguardando prompt:\")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "    response = chat.send_message(prompt)\n",
        "    print(\"Resposta: \", response.text, \"\\n\")\n",
        "    prompt = input(\"Aguardando prompt:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "o3gH1BOly_6G",
        "outputId": "b04d4df6-8f98-4494-ccf3-fb5874ede3f8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resposta:  Tóquio \n",
            "\n",
            "Resposta:  Sushi \n",
            "\n",
            "Resposta:  Japonês \n",
            "\n",
            "Resposta:  Washington, D.C. \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-6088581758f8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resposta: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Aguardando prompt:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLgJ6W5cUDLZ",
        "outputId": "4eb5e652-3ef0-43a0-ff4e-454ee6538e75"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"Qual a capital do jap\\303\\243o?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"T\\303\\263quio\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Qual a comida t\\303\\255pica desse pa\\303\\255s?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Sushi\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Como \\303\\251 comumente chamado quem mora nesse pa\\303\\255s?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Japon\\303\\252s\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Qual a capital dos estados unidos?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Washington, D.C.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}